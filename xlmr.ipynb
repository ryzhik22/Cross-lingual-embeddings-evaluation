{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xlmr.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bd904f0143e548e38064b2879d30d680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6ae25704df5c445daa6258f4b4200a09",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e984b5994c514529bea64ac0877c051f",
              "IPY_MODEL_020718a4f08d4df09fdbbfab98c004f5"
            ]
          }
        },
        "6ae25704df5c445daa6258f4b4200a09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e984b5994c514529bea64ac0877c051f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_173e6f3d50404397b019f2718b3e5bd1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5069051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5069051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ecb523d2a8d94d309145c9484178f46e"
          }
        },
        "020718a4f08d4df09fdbbfab98c004f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_048249d02721454788fcb89b88511bd8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.07M/5.07M [00:12&lt;00:00, 419kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7e13bdd4e29491cb09bb6eba7309726"
          }
        },
        "173e6f3d50404397b019f2718b3e5bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ecb523d2a8d94d309145c9484178f46e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "048249d02721454788fcb89b88511bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7e13bdd4e29491cb09bb6eba7309726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a068f4ac9aaf482cb413579f7ad02c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e0c31be6810d494f88e527728e3d49c0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fb0f30aae74d4cdfaff374bfb147e51d",
              "IPY_MODEL_51acb62f97fb43a78b8b7ec65e7c4703"
            ]
          }
        },
        "e0c31be6810d494f88e527728e3d49c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb0f30aae74d4cdfaff374bfb147e51d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1d14b6a69c3a451f9adf4455e621dbca",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 80948,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 80948,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_98a087eea55743679bbcf945204bb2f7"
          }
        },
        "51acb62f97fb43a78b8b7ec65e7c4703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_53f593d53c5845ebbdbd92d7ed1a73e4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 80948/80948 [01:08&lt;00:00, 1185.12it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bdfcd1fc9a1243ed9dcd552fa16c5b96"
          }
        },
        "1d14b6a69c3a451f9adf4455e621dbca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "98a087eea55743679bbcf945204bb2f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53f593d53c5845ebbdbd92d7ed1a73e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bdfcd1fc9a1243ed9dcd552fa16c5b96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c14580664fc14b8bb947326f4eba1201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dd1587fa09d746fb9f093bc6e1acd1bf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_84db15b84eab4069a51a0ccee45839da",
              "IPY_MODEL_ba77587dbc7245578bdf9b36ffe7c7aa"
            ]
          }
        },
        "dd1587fa09d746fb9f093bc6e1acd1bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84db15b84eab4069a51a0ccee45839da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_26544152972c44c1908af91b4f52bace",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 80948,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 80948,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0aaaddb855bc4c258026e4288323804a"
          }
        },
        "ba77587dbc7245578bdf9b36ffe7c7aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_85bc2f8c943349a48c4ffcae13387b70",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 80948/80948 [1:13:19&lt;00:00, 18.40it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ed4ac967c1342b1a538a941285dbab4"
          }
        },
        "26544152972c44c1908af91b4f52bace": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0aaaddb855bc4c258026e4288323804a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85bc2f8c943349a48c4ffcae13387b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ed4ac967c1342b1a538a941285dbab4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ea6aaf683ab470bb1651c803a3290be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e52d9449100c46129d4cfbab19976094",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_31eb650476154630a0f2d8845f637697",
              "IPY_MODEL_95bfb5de4a4147d5b2317ebf099e2f85"
            ]
          }
        },
        "e52d9449100c46129d4cfbab19976094": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31eb650476154630a0f2d8845f637697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2c44b933d29e4a5dae2a864f7e4d22f8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 512,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 512,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f04dc7148bf45fa84ce0cbcca93b3f5"
          }
        },
        "95bfb5de4a4147d5b2317ebf099e2f85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1f7958cc85d44d8c895676d1089804d0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 512/512 [00:24&lt;00:00, 20.7B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fdc8e33435b447eda7dbee499eb9852e"
          }
        },
        "2c44b933d29e4a5dae2a864f7e4d22f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f04dc7148bf45fa84ce0cbcca93b3f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f7958cc85d44d8c895676d1089804d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fdc8e33435b447eda7dbee499eb9852e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "149ba41a418349cbb9f1da4200b49930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0dc9e29f9ebe41d5842aa144eaf10f07",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a55e0080df1f4a5b91099a4bbb2d956b",
              "IPY_MODEL_98a5e06338ee4b24a6752afa2dfbc5f1"
            ]
          }
        },
        "0dc9e29f9ebe41d5842aa144eaf10f07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a55e0080df1f4a5b91099a4bbb2d956b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cb19ca9ef13f4331ae858b55b3827764",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1115590446,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1115590446,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40c2eae854524166ab55e3c004ec906a"
          }
        },
        "98a5e06338ee4b24a6752afa2dfbc5f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1c939f5a27f74aeba8aff1838ce081fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.12G/1.12G [00:15&lt;00:00, 73.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a2915e0dfb67428b8720dbe37109da11"
          }
        },
        "cb19ca9ef13f4331ae858b55b3827764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40c2eae854524166ab55e3c004ec906a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c939f5a27f74aeba8aff1838ce081fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a2915e0dfb67428b8720dbe37109da11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "880dbb27adc341ff99b4f0723bc7e081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a9ba62e624f740e69fa71df28de116ad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6c621a79fbaa46589e78a6d1edc089f5",
              "IPY_MODEL_b7697b4e9dbb4961a1ab8be5367a3e21"
            ]
          }
        },
        "a9ba62e624f740e69fa71df28de116ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c621a79fbaa46589e78a6d1edc089f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1a0551900c71437bbfa582b74c752ae3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 512,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 512,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a2482b8bbaf14cf9baf3b4d8f948258e"
          }
        },
        "b7697b4e9dbb4961a1ab8be5367a3e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4682ac1bf5744f1f8c905189a99755c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 512/512 [00:32&lt;00:00, 15.7B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f31daa359534b78aca3e46c6437e97c"
          }
        },
        "1a0551900c71437bbfa582b74c752ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a2482b8bbaf14cf9baf3b4d8f948258e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4682ac1bf5744f1f8c905189a99755c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f31daa359534b78aca3e46c6437e97c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a94cfec3c0341dcaa64ce6a9cf26f16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_494e3c34de674a9cabb3382e73cf3d4a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_af1520367e8b4692a750b74be19e76fa",
              "IPY_MODEL_6fef9acf49ff4820b28a0f679ab3620d"
            ]
          }
        },
        "494e3c34de674a9cabb3382e73cf3d4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af1520367e8b4692a750b74be19e76fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_485c07a3eb574e8a883756be55826374",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1115590446,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1115590446,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60a27b1dc5464ebc98ba2877b90d4f94"
          }
        },
        "6fef9acf49ff4820b28a0f679ab3620d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fd8120062f1d4211a16c66644065028b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.12G/1.12G [00:22&lt;00:00, 49.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a2afe58a3faa4c62a70474f836011d08"
          }
        },
        "485c07a3eb574e8a883756be55826374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60a27b1dc5464ebc98ba2877b90d4f94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd8120062f1d4211a16c66644065028b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a2afe58a3faa4c62a70474f836011d08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e41733c61dc42e5bffb96eb30947ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2d397cc5cad147dbb110f29d9fdd7d94",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0e3023c1223846c4ab5bb978b9ba9eb4",
              "IPY_MODEL_b8e37cc712c441c582b0a1128bfe5509"
            ]
          }
        },
        "2d397cc5cad147dbb110f29d9fdd7d94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e3023c1223846c4ab5bb978b9ba9eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_758fda1a456a45f6a8b4417e032c6d22",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10150,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10150,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0cee41494a1244a2b087fa0c0c9d0ef5"
          }
        },
        "b8e37cc712c441c582b0a1128bfe5509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9349dd5e89bf4b3ea70fef54c8c195e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10150/10150 [00:10&lt;00:00, 958.75it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4430fa5f6fed4576bb72aaed63a1de25"
          }
        },
        "758fda1a456a45f6a8b4417e032c6d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0cee41494a1244a2b087fa0c0c9d0ef5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9349dd5e89bf4b3ea70fef54c8c195e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4430fa5f6fed4576bb72aaed63a1de25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a34763eed54d479abedbdd866cb3846b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f60b7e513357405fb1651cec170acdd4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_db0bf61aa71f43c5a4739bf079493852",
              "IPY_MODEL_6bc11978be3c44b6bc6c346a231c9dfe"
            ]
          }
        },
        "f60b7e513357405fb1651cec170acdd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db0bf61aa71f43c5a4739bf079493852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_57281bcfa5854d46ac23ee14e4bc9ca2",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d16397d4f94541afa966bd5695ee1c06"
          }
        },
        "6bc11978be3c44b6bc6c346a231c9dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0859adba0df446e3b0a58fae5c6948f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 318/318 [01:16&lt;00:00,  4.18it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec2d1dd4268f40288cab99aae8fe6424"
          }
        },
        "57281bcfa5854d46ac23ee14e4bc9ca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d16397d4f94541afa966bd5695ee1c06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0859adba0df446e3b0a58fae5c6948f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec2d1dd4268f40288cab99aae8fe6424": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5izbrngVuQuJ",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import torch \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "random.seed(13)\n",
        "np.random.seed(13)\n",
        "torch.manual_seed(13)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "os.environ['PYTHONHASHSEED'] = str(13)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmeGJwlG_XUz",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNPnydy6xyQV",
        "colab_type": "text"
      },
      "source": [
        "### Loading texts, split on train, val and test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaVg7E10vkDU",
        "trusted": true,
        "colab_type": "code",
        "outputId": "64058439-4564-444b-c47d-6ca4624e5b09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget https://www.dropbox.com/s/n8nfxxh5azocrrm/train_LASER.csv?dl=0\n",
        "!wget https://www.dropbox.com/s/v7msk8zxkkiqc6q/X_test_translated.txt?dl=0\n",
        "!wget https://www.dropbox.com/s/je9am5c77ytfcaf/test_LASER.csv?dl=0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-08 10:52:08--  https://www.dropbox.com/s/n8nfxxh5azocrrm/train_LASER.csv?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.1, 2620:100:6018:1::a27d:301\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/n8nfxxh5azocrrm/train_LASER.csv [following]\n",
            "--2020-06-08 10:52:08--  https://www.dropbox.com/s/raw/n8nfxxh5azocrrm/train_LASER.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucaa90e67616b8ce7f2f1f0a7f9b.dl.dropboxusercontent.com/cd/0/inline/A5RhoD_Yb4QqHOhJHFsyAXdXRj8cT_XeBnKP1QG9cqpOimOujVhAWtAxWsGNZ1vds0x_RqpY-1xlJRm6QiYx8nYFjzVCVolptz0BHZx2IITXc4sdqZcc16vC45D0k0aQ1m4/file# [following]\n",
            "--2020-06-08 10:52:09--  https://ucaa90e67616b8ce7f2f1f0a7f9b.dl.dropboxusercontent.com/cd/0/inline/A5RhoD_Yb4QqHOhJHFsyAXdXRj8cT_XeBnKP1QG9cqpOimOujVhAWtAxWsGNZ1vds0x_RqpY-1xlJRm6QiYx8nYFjzVCVolptz0BHZx2IITXc4sdqZcc16vC45D0k0aQ1m4/file\n",
            "Resolving ucaa90e67616b8ce7f2f1f0a7f9b.dl.dropboxusercontent.com (ucaa90e67616b8ce7f2f1f0a7f9b.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\n",
            "Connecting to ucaa90e67616b8ce7f2f1f0a7f9b.dl.dropboxusercontent.com (ucaa90e67616b8ce7f2f1f0a7f9b.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1138912664 (1.1G) [text/plain]\n",
            "Saving to: ‘train_LASER.csv?dl=0’\n",
            "\n",
            "train_LASER.csv?dl= 100%[===================>]   1.06G  67.5MB/s    in 18s     \n",
            "\n",
            "2020-06-08 10:52:27 (60.2 MB/s) - ‘train_LASER.csv?dl=0’ saved [1138912664/1138912664]\n",
            "\n",
            "--2020-06-08 10:52:29--  https://www.dropbox.com/s/v7msk8zxkkiqc6q/X_test_translated.txt?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.1, 2620:100:6018:1::a27d:301\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/v7msk8zxkkiqc6q/X_test_translated.txt [following]\n",
            "--2020-06-08 10:52:29--  https://www.dropbox.com/s/raw/v7msk8zxkkiqc6q/X_test_translated.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucfc1dd9953a551224bbd50ac2b9.dl.dropboxusercontent.com/cd/0/inline/A5QFK1bdcSlRR7L5HwVaeBT7sqxWjlWoIeFhPT7wnm4oqT8wYxyHeq0ecQEueeaHuJ653FL3bqLofUSPQMmOPWp9tPEHioyOQHdEC8jwt7p6Q0mBoAQabbkQKVZlytGoF7c/file# [following]\n",
            "--2020-06-08 10:52:31--  https://ucfc1dd9953a551224bbd50ac2b9.dl.dropboxusercontent.com/cd/0/inline/A5QFK1bdcSlRR7L5HwVaeBT7sqxWjlWoIeFhPT7wnm4oqT8wYxyHeq0ecQEueeaHuJ653FL3bqLofUSPQMmOPWp9tPEHioyOQHdEC8jwt7p6Q0mBoAQabbkQKVZlytGoF7c/file\n",
            "Resolving ucfc1dd9953a551224bbd50ac2b9.dl.dropboxusercontent.com (ucfc1dd9953a551224bbd50ac2b9.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\n",
            "Connecting to ucfc1dd9953a551224bbd50ac2b9.dl.dropboxusercontent.com (ucfc1dd9953a551224bbd50ac2b9.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9437430 (9.0M) [text/plain]\n",
            "Saving to: ‘X_test_translated.txt?dl=0’\n",
            "\n",
            "X_test_translated.t 100%[===================>]   9.00M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-06-08 10:52:31 (71.7 MB/s) - ‘X_test_translated.txt?dl=0’ saved [9437430/9437430]\n",
            "\n",
            "--2020-06-08 10:52:32--  https://www.dropbox.com/s/je9am5c77ytfcaf/test_LASER.csv?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.1, 2620:100:6018:1::a27d:301\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/je9am5c77ytfcaf/test_LASER.csv [following]\n",
            "--2020-06-08 10:52:32--  https://www.dropbox.com/s/raw/je9am5c77ytfcaf/test_LASER.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc9a8ccc049f922252a571343a49.dl.dropboxusercontent.com/cd/0/inline/A5TtxEp2WK3NP6LvvSSDznmY-eHUUXYjwSkXz9y1OkR7z5OHrgd2M-r37eZFtIDwiTkfcelQcCm_psdnN49gI33bJhutLsA1WJCVq7Qqr2oigJcIQ57lm7r4UaOIy1oGLGM/file# [following]\n",
            "--2020-06-08 10:52:33--  https://uc9a8ccc049f922252a571343a49.dl.dropboxusercontent.com/cd/0/inline/A5TtxEp2WK3NP6LvvSSDznmY-eHUUXYjwSkXz9y1OkR7z5OHrgd2M-r37eZFtIDwiTkfcelQcCm_psdnN49gI33bJhutLsA1WJCVq7Qqr2oigJcIQ57lm7r4UaOIy1oGLGM/file\n",
            "Resolving uc9a8ccc049f922252a571343a49.dl.dropboxusercontent.com (uc9a8ccc049f922252a571343a49.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\n",
            "Connecting to uc9a8ccc049f922252a571343a49.dl.dropboxusercontent.com (uc9a8ccc049f922252a571343a49.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18325202 (17M) [text/plain]\n",
            "Saving to: ‘test_LASER.csv?dl=0’\n",
            "\n",
            "test_LASER.csv?dl=0 100%[===================>]  17.48M  56.4MB/s    in 0.3s    \n",
            "\n",
            "2020-06-08 10:52:33 (56.4 MB/s) - ‘test_LASER.csv?dl=0’ saved [18325202/18325202]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuR1LgGZufBF",
        "outputId": "145b98b0-6bd8-44f6-cf85-0f2bc9de6a70",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#открываем файл с train dataset\n",
        "import pandas as pd\n",
        "df_train = pd.read_csv(\"train_LASER.csv?dl=0\").dropna()\n",
        "train_texts = list(df_train['abstracts'])\n",
        "train_labels = list(df_train['labels'])\n",
        "\n",
        "len(train_texts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80948"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoIn7HBivCxN",
        "outputId": "d7888077-e9bb-4e64-b2c3-aec491822726",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#открываем файл с test_dataset\n",
        "df_test = pd.read_csv(\"test_LASER.csv?dl=0\").dropna()\n",
        "test_texts = list(df_test['lemm_abstracts'])              #лемм там нет, просто название неправильное не дала\n",
        "test_labels = list(df_test['labels'])\n",
        "\n",
        "len(test_texts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10150"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "buSTo_L1hKeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleaning(text):\n",
        "    clean_txt = []\n",
        "    for sentence in text.split('.'):\n",
        "        sentence = re.sub(r'[•⋅−]', ' ', sentence)\n",
        "        pattern = re.compile(r'(\\s,){2,}')                 # регулярка для того чтобы несколько подряд запятых заменять на одну\n",
        "        sentence = re.sub(pattern, ', ', sentence)\n",
        "        sent = sentence.strip()\n",
        "        sent = re.sub(r'( )+', ' ', sent)\n",
        "        sent = re.sub(' ,', ',', sent)\n",
        "        if len(sent.lstrip(',').rstrip(',').strip().split()) > 2 and sent != 'ф лы, ил': \n",
        "             clean_txt.append(sent.lstrip(',').rstrip(',').strip())\n",
        "    return '. '.join(clean_txt)         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5HQcp5zbhKev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook as tqdm\n",
        "import re\n",
        "test_texts = [cleaning(text) for text in test_texts]\n",
        "train_texts = [cleaning(text) for text in train_texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4yM9ZYNmhKe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('X_test_translated.txt?dl=0', encoding='utf-8') as of:\n",
        "    translated_texts = of.readlines()\n",
        "    of.close()\n",
        "    \n",
        "translated_texts = [cleaning(text.strip()) for text in translated_texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP9-3YkOqwj1",
        "colab_type": "code",
        "outputId": "3d80ac52-9a24-406d-a431-05ca937ae6eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_labels = [label[0] for label in train_labels]\n",
        "test_labels = [label[0] for label in test_labels]\n",
        "train_labels[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['G', 'H', 'B', 'H', 'A', 'F', 'G', 'B', 'E', 'B']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYELfK3g51Z5",
        "outputId": "d0212749-d26c-4854-b129-a46fda006cc0",
        "trusted": true,
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(train_labels)\n",
        "#add_labels = label_encoder.fit_transform(df_add['us_code'])\n",
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 7, 1, 7, 0, 5, 6, 1, 4, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xlttQgmrFI8",
        "colab_type": "code",
        "outputId": "e58b08c5-29da-4bae-baa6-08cb1a08cd75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "from collections import Counter\n",
        "Counter(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 10556,\n",
              "         1: 17284,\n",
              "         2: 7792,\n",
              "         3: 1368,\n",
              "         4: 3764,\n",
              "         5: 11810,\n",
              "         6: 13760,\n",
              "         7: 14614})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI612Lvk15E0",
        "trusted": true,
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test = label_encoder.transform(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PPRGCAt6CKU",
        "colab_type": "code",
        "outputId": "f8d7fdb6-b31b-45e7-df1b-2b76b8c643fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHgYcY6b6HSS",
        "colab_type": "code",
        "outputId": "834035dc-42f5-48e5-89eb-2cc50fd7f23a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHMex_h16KQ_",
        "colab_type": "code",
        "outputId": "cedb874f-f651-40e0-b57d-dabdc5c35188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "sentences_train = np.array(train_texts)\n",
        "labels_train = y_train\n",
        "sentences_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80948,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n3s_pXt6NI8",
        "colab_type": "code",
        "outputId": "3d492eb2-a2ea-407c-8ecf-834e78b9ea31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "#sentences_test = np.array(test_texts)\n",
        "sentences_test = np.array(translated_texts)\n",
        "labels_test = y_test\n",
        "sentences_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10150,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZrQ_c796PlP",
        "colab_type": "code",
        "outputId": "4296f9e2-6ee3-49e9-836c-096aed32ad55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "bd904f0143e548e38064b2879d30d680",
            "6ae25704df5c445daa6258f4b4200a09",
            "e984b5994c514529bea64ac0877c051f",
            "020718a4f08d4df09fdbbfab98c004f5",
            "173e6f3d50404397b019f2718b3e5bd1",
            "ecb523d2a8d94d309145c9484178f46e",
            "048249d02721454788fcb89b88511bd8",
            "b7e13bdd4e29491cb09bb6eba7309726"
          ]
        }
      },
      "source": [
        "from transformers import XLMRobertaTokenizer\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading XLM-R tokenizer...')\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base', do_lower_case=True)\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading XLM-R tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd904f0143e548e38064b2879d30d680",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXLCdWdF6Sbk",
        "colab_type": "code",
        "outputId": "7d102420-aa80-475b-9b14-9551c1758110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences_train[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences_train[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences_train[0])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  a wireless type prepaid ic card system enhances the convenience of users and assures the safe payment of tolls by vehicles including bikes when introduced for toll roads. this toll collecting system is composed of a card processor that is arranged in a booth for the toll collection process and has an antenna unit for executing the card process through the wireless communication with ic cards, antenna units arranged at the left and right roadsides of the booth for executing the card process through the wireless communication with ic cards, a vehicle class discriminator for discriminating classes of vehicles entering into a traffic lane, and a traffic lane controller that selects an antenna unit to perform the card process according to a discriminated vehicle class and controls the card process\n",
            "Tokenized:  ['▁a', '▁wireless', '▁type', '▁pre', 'paid', '▁', 'ic', '▁card', '▁system', '▁enhance', 's', '▁the', '▁conveni', 'ence', '▁of', '▁users', '▁and', '▁assure', 's', '▁the', '▁safe', '▁payment', '▁of', '▁toll', 's', '▁by', '▁vehicles', '▁including', '▁bike', 's', '▁when', '▁introduce', 'd', '▁for', '▁toll', '▁road', 's', '.', '▁this', '▁toll', '▁collect', 'ing', '▁system', '▁is', '▁compose', 'd', '▁of', '▁a', '▁card', '▁processo', 'r', '▁that', '▁is', '▁arrange', 'd', '▁in', '▁a', '▁boot', 'h', '▁for', '▁the', '▁toll', '▁collection', '▁process', '▁and', '▁has', '▁an', '▁ante', 'nna', '▁unit', '▁for', '▁execut', 'ing', '▁the', '▁card', '▁process', '▁through', '▁the', '▁wireless', '▁communication', '▁with', '▁', 'ic', '▁cards', ',', '▁ante', 'nna', '▁unit', 's', '▁arrange', 'd', '▁at', '▁the', '▁left', '▁and', '▁right', '▁road', 'side', 's', '▁of', '▁the', '▁boot', 'h', '▁for', '▁execut', 'ing', '▁the', '▁card', '▁process', '▁through', '▁the', '▁wireless', '▁communication', '▁with', '▁', 'ic', '▁cards', ',', '▁a', '▁vehicle', '▁class', '▁discrimina', 'tor', '▁for', '▁discrimina', 'ting', '▁classes', '▁of', '▁vehicles', '▁en', 'tering', '▁into', '▁a', '▁traffic', '▁la', 'ne', ',', '▁and', '▁a', '▁traffic', '▁la', 'ne', '▁controller', '▁that', '▁select', 's', '▁an', '▁ante', 'nna', '▁unit', '▁to', '▁perform', '▁the', '▁card', '▁process', '▁according', '▁to', '▁a', '▁discrimina', 'ted', '▁vehicle', '▁class', '▁and', '▁control', 's', '▁the', '▁card', '▁process']\n",
            "Token IDs:  [10, 135051, 10644, 479, 138925, 6, 1771, 20596, 5426, 156856, 7, 70, 50080, 6620, 111, 72095, 136, 92784, 7, 70, 46002, 81997, 111, 43584, 7, 390, 117001, 26719, 15528, 7, 3229, 65508, 71, 100, 43584, 33816, 7, 5, 903, 43584, 43799, 214, 5426, 83, 150350, 71, 111, 10, 20596, 14543, 42, 450, 83, 137356, 71, 23, 10, 49935, 127, 100, 70, 43584, 42486, 9433, 136, 1556, 142, 4030, 11089, 25072, 100, 71924, 214, 70, 20596, 9433, 8305, 70, 135051, 36398, 678, 6, 1771, 126381, 4, 4030, 11089, 25072, 7, 137356, 71, 99, 70, 25737, 136, 7108, 33816, 8752, 7, 111, 70, 49935, 127, 100, 71924, 214, 70, 20596, 9433, 8305, 70, 135051, 36398, 678, 6, 1771, 126381, 4, 10, 80939, 18507, 55970, 1290, 100, 55970, 1916, 61112, 111, 117001, 22, 33558, 3934, 10, 83629, 21, 86, 4, 136, 10, 83629, 21, 86, 185373, 450, 36849, 7, 142, 4030, 11089, 25072, 47, 51339, 70, 20596, 9433, 59499, 47, 10, 55970, 3674, 80939, 18507, 136, 6226, 7, 70, 20596, 9433]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz5hCq-q6VEW",
        "colab_type": "code",
        "outputId": "03fa2dc5-7754-468d-cec0-3421a1b33501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178,
          "referenced_widgets": [
            "a068f4ac9aaf482cb413579f7ad02c55",
            "e0c31be6810d494f88e527728e3d49c0",
            "fb0f30aae74d4cdfaff374bfb147e51d",
            "51acb62f97fb43a78b8b7ec65e7c4703",
            "1d14b6a69c3a451f9adf4455e621dbca",
            "98a087eea55743679bbcf945204bb2f7",
            "53f593d53c5845ebbdbd92d7ed1a73e4",
            "bdfcd1fc9a1243ed9dcd552fa16c5b96"
          ]
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "\n",
        "input_ids_train = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in tqdm(sentences_train):\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        max_length = 256         # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids_train.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences_train[0])\n",
        "print('Token IDs:', input_ids_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a068f4ac9aaf482cb413579f7ad02c55",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=80948.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Original:  a wireless type prepaid ic card system enhances the convenience of users and assures the safe payment of tolls by vehicles including bikes when introduced for toll roads. this toll collecting system is composed of a card processor that is arranged in a booth for the toll collection process and has an antenna unit for executing the card process through the wireless communication with ic cards, antenna units arranged at the left and right roadsides of the booth for executing the card process through the wireless communication with ic cards, a vehicle class discriminator for discriminating classes of vehicles entering into a traffic lane, and a traffic lane controller that selects an antenna unit to perform the card process according to a discriminated vehicle class and controls the card process\n",
            "Token IDs: [0, 10, 135051, 10644, 479, 138925, 6, 1771, 20596, 5426, 156856, 7, 70, 50080, 6620, 111, 72095, 136, 92784, 7, 70, 46002, 81997, 111, 43584, 7, 390, 117001, 26719, 15528, 7, 3229, 65508, 71, 100, 43584, 33816, 7, 5, 903, 43584, 43799, 214, 5426, 83, 150350, 71, 111, 10, 20596, 14543, 42, 450, 83, 137356, 71, 23, 10, 49935, 127, 100, 70, 43584, 42486, 9433, 136, 1556, 142, 4030, 11089, 25072, 100, 71924, 214, 70, 20596, 9433, 8305, 70, 135051, 36398, 678, 6, 1771, 126381, 4, 4030, 11089, 25072, 7, 137356, 71, 99, 70, 25737, 136, 7108, 33816, 8752, 7, 111, 70, 49935, 127, 100, 71924, 214, 70, 20596, 9433, 8305, 70, 135051, 36398, 678, 6, 1771, 126381, 4, 10, 80939, 18507, 55970, 1290, 100, 55970, 1916, 61112, 111, 117001, 22, 33558, 3934, 10, 83629, 21, 86, 4, 136, 10, 83629, 21, 86, 185373, 450, 36849, 7, 142, 4030, 11089, 25072, 47, 51339, 70, 20596, 9433, 59499, 47, 10, 55970, 3674, 80939, 18507, 136, 6226, 7, 70, 20596, 9433, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqZzN62f6X_l",
        "colab_type": "code",
        "outputId": "026a70cf-8e5d-44e3-e984-63506ce335ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_LEN = 256\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids_train = pad_sequences(input_ids_train, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=1, truncating=\"post\", padding=\"post\")\n",
        "#input_ids_test = pad_sequences(input_ids_test, maxlen=MAX_LEN, dtype=\"long\", \n",
        "        #                  value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 256 values...\n",
            "\n",
            "Padding token: \"<pad>\", ID: 1\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7Zcvscn6ccQ",
        "colab_type": "code",
        "outputId": "d6c437d9-18f8-4a13-f11c-38cc9b6403c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "c14580664fc14b8bb947326f4eba1201",
            "dd1587fa09d746fb9f093bc6e1acd1bf",
            "84db15b84eab4069a51a0ccee45839da",
            "ba77587dbc7245578bdf9b36ffe7c7aa",
            "26544152972c44c1908af91b4f52bace",
            "0aaaddb855bc4c258026e4288323804a",
            "85bc2f8c943349a48c4ffcae13387b70",
            "6ed4ac967c1342b1a538a941285dbab4"
          ]
        }
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks_tr = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in tqdm(input_ids_train):\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id != 1) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks_tr.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c14580664fc14b8bb947326f4eba1201",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=80948.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NuKR4v86fPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 85% for training and 15% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids_train, labels_train, \n",
        "                                                            random_state=42, test_size=0.15, shuffle=True, stratify=y_train)\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks_tr, labels_train,\n",
        "                                             random_state=42, test_size=0.15, shuffle=True, stratify=y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhxDPBbWX7eX",
        "colab_type": "code",
        "outputId": "e9d18b0a-0019-4588-b72d-c9558df10eb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(train_inputs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68805"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wKJRVHX6gP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E09A6dQG6i8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9c0fwIh6lbJ",
        "colab_type": "code",
        "outputId": "560a0d5d-4833-4825-bb7a-d1fa18d82576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1ea6aaf683ab470bb1651c803a3290be",
            "e52d9449100c46129d4cfbab19976094",
            "31eb650476154630a0f2d8845f637697",
            "95bfb5de4a4147d5b2317ebf099e2f85",
            "2c44b933d29e4a5dae2a864f7e4d22f8",
            "3f04dc7148bf45fa84ce0cbcca93b3f5",
            "1f7958cc85d44d8c895676d1089804d0",
            "fdc8e33435b447eda7dbee499eb9852e",
            "149ba41a418349cbb9f1da4200b49930",
            "0dc9e29f9ebe41d5842aa144eaf10f07",
            "a55e0080df1f4a5b91099a4bbb2d956b",
            "98a5e06338ee4b24a6752afa2dfbc5f1",
            "cb19ca9ef13f4331ae858b55b3827764",
            "40c2eae854524166ab55e3c004ec906a",
            "1c939f5a27f74aeba8aff1838ce081fa",
            "a2915e0dfb67428b8720dbe37109da11"
          ]
        }
      },
      "source": [
        "from transformers import XLMRobertaForSequenceClassification, AdamW\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = XLMRobertaForSequenceClassification.from_pretrained(\n",
        "    \"xlm-roberta-base\", # Use the 12-layer BERT model, with an uncased vocab. #bert-base-multiligual-cased\n",
        "    num_labels = 8, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ea6aaf683ab470bb1651c803a3290be",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=512.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "149ba41a418349cbb9f1da4200b49930",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1115590446.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=8, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygo4dnhepugE",
        "colab_type": "code",
        "outputId": "5edf251f-8980-4286-acba-cf76b7908890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.roberta.embeddings.word_embeddings.requires_grad = False\n",
        "model.roberta.embeddings.word_embeddings.requires_grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWdBILmPtPDL",
        "colab_type": "code",
        "outputId": "9f21acb0-86f7-4fe3-cbb9-bae9bbe8a681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "880dbb27adc341ff99b4f0723bc7e081",
            "a9ba62e624f740e69fa71df28de116ad",
            "6c621a79fbaa46589e78a6d1edc089f5",
            "b7697b4e9dbb4961a1ab8be5367a3e21",
            "1a0551900c71437bbfa582b74c752ae3",
            "a2482b8bbaf14cf9baf3b4d8f948258e",
            "4682ac1bf5744f1f8c905189a99755c8",
            "4f31daa359534b78aca3e46c6437e97c",
            "9a94cfec3c0341dcaa64ce6a9cf26f16",
            "494e3c34de674a9cabb3382e73cf3d4a",
            "af1520367e8b4692a750b74be19e76fa",
            "6fef9acf49ff4820b28a0f679ab3620d",
            "485c07a3eb574e8a883756be55826374",
            "60a27b1dc5464ebc98ba2877b90d4f94",
            "fd8120062f1d4211a16c66644065028b",
            "a2afe58a3faa4c62a70474f836011d08"
          ]
        }
      },
      "source": [
        "from transformers import XLMRobertaModel, AdamW\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "xlmr = XLMRobertaModel.from_pretrained(\n",
        "    \"xlm-roberta-base\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "880dbb27adc341ff99b4f0723bc7e081",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=512.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a94cfec3c0341dcaa64ce6a9cf26f16",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1115590446.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRStpRvqtRtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, hidden_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.xlmr = xlmr\n",
        "        self.lstm = nn.LSTM(768, hidden_dim, bidirectional=True, batch_first=True)\n",
        "        self.linear = nn.Linear(2*hidden_dim, 225)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "            \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        xlmr_output = self.dropout(self.xlmr(input_ids, attention_mask)[0])\n",
        "        output, (hidden, _) = self.lstm(xlmr_output)\n",
        "      #  print(hidden.shape)\n",
        "        final = torch.cat([hidden[0], hidden[1]], axis=1)\n",
        "        preds = self.linear(final).squeeze(0)\n",
        "        return F.log_softmax(preds, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lJB6sVLtXsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTM(hidden_dim=512, dropout = 0.2).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpbjc4bC6ojS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8, # args.adam_epsilon  - default is 1e-8.\n",
        "               weight_decay=1e-3)\n",
        "\n",
        "#loss_func = nn.NLLLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA302SpmmbdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#веса для лосс функции\n",
        "distrib_class = dict(Counter(y_train))\n",
        "values_class = np.zeros((len(distrib_class)))\n",
        "for key in sorted(distrib_class.keys()):\n",
        "    values_class[key] = distrib_class[key]\n",
        "    \n",
        "weights = torch.FloatTensor(np.min(values_class)/values_class).cuda()\n",
        "\n",
        "loss_func = nn.NLLLoss(weight = weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msgjiIHV6rmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWuRJV8T6xGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHWKi1_f60HG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXXeesbz62sp",
        "colab_type": "code",
        "outputId": "9d239b50-98a4-4ff5-8980-a9b42fa8b141",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "loss_history = []\n",
        " \n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "    #    outputs = model(b_input_ids, \n",
        "     #               attention_mask=b_input_mask)\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "     #   loss = loss_func(outputs, b_labels)\n",
        "        loss_history.append(loss)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
        "    \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "       #     logits = model(b_input_ids, \n",
        "        #                    attention_mask=b_input_mask)\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "\n",
        "        logits = outputs[0]\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.4f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\") "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of  8,601.    Elapsed: 0:00:10.\n",
            "  Batch    80  of  8,601.    Elapsed: 0:00:21.\n",
            "  Batch   120  of  8,601.    Elapsed: 0:00:31.\n",
            "  Batch   160  of  8,601.    Elapsed: 0:00:41.\n",
            "  Batch   200  of  8,601.    Elapsed: 0:00:51.\n",
            "  Batch   240  of  8,601.    Elapsed: 0:01:01.\n",
            "  Batch   280  of  8,601.    Elapsed: 0:01:11.\n",
            "  Batch   320  of  8,601.    Elapsed: 0:01:21.\n",
            "  Batch   360  of  8,601.    Elapsed: 0:01:31.\n",
            "  Batch   400  of  8,601.    Elapsed: 0:01:41.\n",
            "  Batch   440  of  8,601.    Elapsed: 0:01:51.\n",
            "  Batch   480  of  8,601.    Elapsed: 0:02:01.\n",
            "  Batch   520  of  8,601.    Elapsed: 0:02:11.\n",
            "  Batch   560  of  8,601.    Elapsed: 0:02:21.\n",
            "  Batch   600  of  8,601.    Elapsed: 0:02:32.\n",
            "  Batch   640  of  8,601.    Elapsed: 0:02:42.\n",
            "  Batch   680  of  8,601.    Elapsed: 0:02:52.\n",
            "  Batch   720  of  8,601.    Elapsed: 0:03:02.\n",
            "  Batch   760  of  8,601.    Elapsed: 0:03:12.\n",
            "  Batch   800  of  8,601.    Elapsed: 0:03:22.\n",
            "  Batch   840  of  8,601.    Elapsed: 0:03:32.\n",
            "  Batch   880  of  8,601.    Elapsed: 0:03:42.\n",
            "  Batch   920  of  8,601.    Elapsed: 0:03:52.\n",
            "  Batch   960  of  8,601.    Elapsed: 0:04:02.\n",
            "  Batch 1,000  of  8,601.    Elapsed: 0:04:12.\n",
            "  Batch 1,040  of  8,601.    Elapsed: 0:04:22.\n",
            "  Batch 1,080  of  8,601.    Elapsed: 0:04:32.\n",
            "  Batch 1,120  of  8,601.    Elapsed: 0:04:42.\n",
            "  Batch 1,160  of  8,601.    Elapsed: 0:04:53.\n",
            "  Batch 1,200  of  8,601.    Elapsed: 0:05:03.\n",
            "  Batch 1,240  of  8,601.    Elapsed: 0:05:13.\n",
            "  Batch 1,280  of  8,601.    Elapsed: 0:05:23.\n",
            "  Batch 1,320  of  8,601.    Elapsed: 0:05:33.\n",
            "  Batch 1,360  of  8,601.    Elapsed: 0:05:43.\n",
            "  Batch 1,400  of  8,601.    Elapsed: 0:05:53.\n",
            "  Batch 1,440  of  8,601.    Elapsed: 0:06:03.\n",
            "  Batch 1,480  of  8,601.    Elapsed: 0:06:13.\n",
            "  Batch 1,520  of  8,601.    Elapsed: 0:06:23.\n",
            "  Batch 1,560  of  8,601.    Elapsed: 0:06:33.\n",
            "  Batch 1,600  of  8,601.    Elapsed: 0:06:43.\n",
            "  Batch 1,640  of  8,601.    Elapsed: 0:06:53.\n",
            "  Batch 1,680  of  8,601.    Elapsed: 0:07:04.\n",
            "  Batch 1,720  of  8,601.    Elapsed: 0:07:14.\n",
            "  Batch 1,760  of  8,601.    Elapsed: 0:07:24.\n",
            "  Batch 1,800  of  8,601.    Elapsed: 0:07:34.\n",
            "  Batch 1,840  of  8,601.    Elapsed: 0:07:44.\n",
            "  Batch 1,880  of  8,601.    Elapsed: 0:07:54.\n",
            "  Batch 1,920  of  8,601.    Elapsed: 0:08:04.\n",
            "  Batch 1,960  of  8,601.    Elapsed: 0:08:14.\n",
            "  Batch 2,000  of  8,601.    Elapsed: 0:08:24.\n",
            "  Batch 2,040  of  8,601.    Elapsed: 0:08:34.\n",
            "  Batch 2,080  of  8,601.    Elapsed: 0:08:44.\n",
            "  Batch 2,120  of  8,601.    Elapsed: 0:08:54.\n",
            "  Batch 2,160  of  8,601.    Elapsed: 0:09:05.\n",
            "  Batch 2,200  of  8,601.    Elapsed: 0:09:15.\n",
            "  Batch 2,240  of  8,601.    Elapsed: 0:09:25.\n",
            "  Batch 2,280  of  8,601.    Elapsed: 0:09:35.\n",
            "  Batch 2,320  of  8,601.    Elapsed: 0:09:45.\n",
            "  Batch 2,360  of  8,601.    Elapsed: 0:09:55.\n",
            "  Batch 2,400  of  8,601.    Elapsed: 0:10:05.\n",
            "  Batch 2,440  of  8,601.    Elapsed: 0:10:15.\n",
            "  Batch 2,480  of  8,601.    Elapsed: 0:10:25.\n",
            "  Batch 2,520  of  8,601.    Elapsed: 0:10:35.\n",
            "  Batch 2,560  of  8,601.    Elapsed: 0:10:45.\n",
            "  Batch 2,600  of  8,601.    Elapsed: 0:10:55.\n",
            "  Batch 2,640  of  8,601.    Elapsed: 0:11:06.\n",
            "  Batch 2,680  of  8,601.    Elapsed: 0:11:16.\n",
            "  Batch 2,720  of  8,601.    Elapsed: 0:11:26.\n",
            "  Batch 2,760  of  8,601.    Elapsed: 0:11:36.\n",
            "  Batch 2,800  of  8,601.    Elapsed: 0:11:46.\n",
            "  Batch 2,840  of  8,601.    Elapsed: 0:11:56.\n",
            "  Batch 2,880  of  8,601.    Elapsed: 0:12:06.\n",
            "  Batch 2,920  of  8,601.    Elapsed: 0:12:16.\n",
            "  Batch 2,960  of  8,601.    Elapsed: 0:12:26.\n",
            "  Batch 3,000  of  8,601.    Elapsed: 0:12:36.\n",
            "  Batch 3,040  of  8,601.    Elapsed: 0:12:46.\n",
            "  Batch 3,080  of  8,601.    Elapsed: 0:12:56.\n",
            "  Batch 3,120  of  8,601.    Elapsed: 0:13:07.\n",
            "  Batch 3,160  of  8,601.    Elapsed: 0:13:17.\n",
            "  Batch 3,200  of  8,601.    Elapsed: 0:13:27.\n",
            "  Batch 3,240  of  8,601.    Elapsed: 0:13:37.\n",
            "  Batch 3,280  of  8,601.    Elapsed: 0:13:47.\n",
            "  Batch 3,320  of  8,601.    Elapsed: 0:13:57.\n",
            "  Batch 3,360  of  8,601.    Elapsed: 0:14:07.\n",
            "  Batch 3,400  of  8,601.    Elapsed: 0:14:17.\n",
            "  Batch 3,440  of  8,601.    Elapsed: 0:14:27.\n",
            "  Batch 3,480  of  8,601.    Elapsed: 0:14:37.\n",
            "  Batch 3,520  of  8,601.    Elapsed: 0:14:47.\n",
            "  Batch 3,560  of  8,601.    Elapsed: 0:14:58.\n",
            "  Batch 3,600  of  8,601.    Elapsed: 0:15:08.\n",
            "  Batch 3,640  of  8,601.    Elapsed: 0:15:18.\n",
            "  Batch 3,680  of  8,601.    Elapsed: 0:15:28.\n",
            "  Batch 3,720  of  8,601.    Elapsed: 0:15:38.\n",
            "  Batch 3,760  of  8,601.    Elapsed: 0:15:48.\n",
            "  Batch 3,800  of  8,601.    Elapsed: 0:15:58.\n",
            "  Batch 3,840  of  8,601.    Elapsed: 0:16:08.\n",
            "  Batch 3,880  of  8,601.    Elapsed: 0:16:18.\n",
            "  Batch 3,920  of  8,601.    Elapsed: 0:16:28.\n",
            "  Batch 3,960  of  8,601.    Elapsed: 0:16:38.\n",
            "  Batch 4,000  of  8,601.    Elapsed: 0:16:48.\n",
            "  Batch 4,040  of  8,601.    Elapsed: 0:16:59.\n",
            "  Batch 4,080  of  8,601.    Elapsed: 0:17:09.\n",
            "  Batch 4,120  of  8,601.    Elapsed: 0:17:19.\n",
            "  Batch 4,160  of  8,601.    Elapsed: 0:17:29.\n",
            "  Batch 4,200  of  8,601.    Elapsed: 0:17:39.\n",
            "  Batch 4,240  of  8,601.    Elapsed: 0:17:49.\n",
            "  Batch 4,280  of  8,601.    Elapsed: 0:17:59.\n",
            "  Batch 4,320  of  8,601.    Elapsed: 0:18:09.\n",
            "  Batch 4,360  of  8,601.    Elapsed: 0:18:19.\n",
            "  Batch 4,400  of  8,601.    Elapsed: 0:18:29.\n",
            "  Batch 4,440  of  8,601.    Elapsed: 0:18:39.\n",
            "  Batch 4,480  of  8,601.    Elapsed: 0:18:49.\n",
            "  Batch 4,520  of  8,601.    Elapsed: 0:19:00.\n",
            "  Batch 4,560  of  8,601.    Elapsed: 0:19:10.\n",
            "  Batch 4,600  of  8,601.    Elapsed: 0:19:20.\n",
            "  Batch 4,640  of  8,601.    Elapsed: 0:19:30.\n",
            "  Batch 4,680  of  8,601.    Elapsed: 0:19:40.\n",
            "  Batch 4,720  of  8,601.    Elapsed: 0:19:50.\n",
            "  Batch 4,760  of  8,601.    Elapsed: 0:20:00.\n",
            "  Batch 4,800  of  8,601.    Elapsed: 0:20:10.\n",
            "  Batch 4,840  of  8,601.    Elapsed: 0:20:20.\n",
            "  Batch 4,880  of  8,601.    Elapsed: 0:20:30.\n",
            "  Batch 4,920  of  8,601.    Elapsed: 0:20:40.\n",
            "  Batch 4,960  of  8,601.    Elapsed: 0:20:50.\n",
            "  Batch 5,000  of  8,601.    Elapsed: 0:21:01.\n",
            "  Batch 5,040  of  8,601.    Elapsed: 0:21:11.\n",
            "  Batch 5,080  of  8,601.    Elapsed: 0:21:21.\n",
            "  Batch 5,120  of  8,601.    Elapsed: 0:21:31.\n",
            "  Batch 5,160  of  8,601.    Elapsed: 0:21:41.\n",
            "  Batch 5,200  of  8,601.    Elapsed: 0:21:51.\n",
            "  Batch 5,240  of  8,601.    Elapsed: 0:22:01.\n",
            "  Batch 5,280  of  8,601.    Elapsed: 0:22:11.\n",
            "  Batch 5,320  of  8,601.    Elapsed: 0:22:21.\n",
            "  Batch 5,360  of  8,601.    Elapsed: 0:22:31.\n",
            "  Batch 5,400  of  8,601.    Elapsed: 0:22:41.\n",
            "  Batch 5,440  of  8,601.    Elapsed: 0:22:51.\n",
            "  Batch 5,480  of  8,601.    Elapsed: 0:23:01.\n",
            "  Batch 5,520  of  8,601.    Elapsed: 0:23:11.\n",
            "  Batch 5,560  of  8,601.    Elapsed: 0:23:22.\n",
            "  Batch 5,600  of  8,601.    Elapsed: 0:23:32.\n",
            "  Batch 5,640  of  8,601.    Elapsed: 0:23:42.\n",
            "  Batch 5,680  of  8,601.    Elapsed: 0:23:52.\n",
            "  Batch 5,720  of  8,601.    Elapsed: 0:24:02.\n",
            "  Batch 5,760  of  8,601.    Elapsed: 0:24:12.\n",
            "  Batch 5,800  of  8,601.    Elapsed: 0:24:22.\n",
            "  Batch 5,840  of  8,601.    Elapsed: 0:24:32.\n",
            "  Batch 5,880  of  8,601.    Elapsed: 0:24:42.\n",
            "  Batch 5,920  of  8,601.    Elapsed: 0:24:52.\n",
            "  Batch 5,960  of  8,601.    Elapsed: 0:25:02.\n",
            "  Batch 6,000  of  8,601.    Elapsed: 0:25:12.\n",
            "  Batch 6,040  of  8,601.    Elapsed: 0:25:22.\n",
            "  Batch 6,080  of  8,601.    Elapsed: 0:25:33.\n",
            "  Batch 6,120  of  8,601.    Elapsed: 0:25:43.\n",
            "  Batch 6,160  of  8,601.    Elapsed: 0:25:53.\n",
            "  Batch 6,200  of  8,601.    Elapsed: 0:26:03.\n",
            "  Batch 6,240  of  8,601.    Elapsed: 0:26:13.\n",
            "  Batch 6,280  of  8,601.    Elapsed: 0:26:23.\n",
            "  Batch 6,320  of  8,601.    Elapsed: 0:26:33.\n",
            "  Batch 6,360  of  8,601.    Elapsed: 0:26:43.\n",
            "  Batch 6,400  of  8,601.    Elapsed: 0:26:53.\n",
            "  Batch 6,440  of  8,601.    Elapsed: 0:27:03.\n",
            "  Batch 6,480  of  8,601.    Elapsed: 0:27:13.\n",
            "  Batch 6,520  of  8,601.    Elapsed: 0:27:23.\n",
            "  Batch 6,560  of  8,601.    Elapsed: 0:27:33.\n",
            "  Batch 6,600  of  8,601.    Elapsed: 0:27:44.\n",
            "  Batch 6,640  of  8,601.    Elapsed: 0:27:54.\n",
            "  Batch 6,680  of  8,601.    Elapsed: 0:28:04.\n",
            "  Batch 6,720  of  8,601.    Elapsed: 0:28:14.\n",
            "  Batch 6,760  of  8,601.    Elapsed: 0:28:24.\n",
            "  Batch 6,800  of  8,601.    Elapsed: 0:28:34.\n",
            "  Batch 6,840  of  8,601.    Elapsed: 0:28:44.\n",
            "  Batch 6,880  of  8,601.    Elapsed: 0:28:54.\n",
            "  Batch 6,920  of  8,601.    Elapsed: 0:29:04.\n",
            "  Batch 6,960  of  8,601.    Elapsed: 0:29:14.\n",
            "  Batch 7,000  of  8,601.    Elapsed: 0:29:24.\n",
            "  Batch 7,040  of  8,601.    Elapsed: 0:29:34.\n",
            "  Batch 7,080  of  8,601.    Elapsed: 0:29:44.\n",
            "  Batch 7,120  of  8,601.    Elapsed: 0:29:55.\n",
            "  Batch 7,160  of  8,601.    Elapsed: 0:30:05.\n",
            "  Batch 7,200  of  8,601.    Elapsed: 0:30:15.\n",
            "  Batch 7,240  of  8,601.    Elapsed: 0:30:25.\n",
            "  Batch 7,280  of  8,601.    Elapsed: 0:30:35.\n",
            "  Batch 7,320  of  8,601.    Elapsed: 0:30:45.\n",
            "  Batch 7,360  of  8,601.    Elapsed: 0:30:55.\n",
            "  Batch 7,400  of  8,601.    Elapsed: 0:31:05.\n",
            "  Batch 7,440  of  8,601.    Elapsed: 0:31:15.\n",
            "  Batch 7,480  of  8,601.    Elapsed: 0:31:25.\n",
            "  Batch 7,520  of  8,601.    Elapsed: 0:31:35.\n",
            "  Batch 7,560  of  8,601.    Elapsed: 0:31:45.\n",
            "  Batch 7,600  of  8,601.    Elapsed: 0:31:55.\n",
            "  Batch 7,640  of  8,601.    Elapsed: 0:32:05.\n",
            "  Batch 7,680  of  8,601.    Elapsed: 0:32:16.\n",
            "  Batch 7,720  of  8,601.    Elapsed: 0:32:26.\n",
            "  Batch 7,760  of  8,601.    Elapsed: 0:32:36.\n",
            "  Batch 7,800  of  8,601.    Elapsed: 0:32:46.\n",
            "  Batch 7,840  of  8,601.    Elapsed: 0:32:56.\n",
            "  Batch 7,880  of  8,601.    Elapsed: 0:33:06.\n",
            "  Batch 7,920  of  8,601.    Elapsed: 0:33:16.\n",
            "  Batch 7,960  of  8,601.    Elapsed: 0:33:26.\n",
            "  Batch 8,000  of  8,601.    Elapsed: 0:33:36.\n",
            "  Batch 8,040  of  8,601.    Elapsed: 0:33:46.\n",
            "  Batch 8,080  of  8,601.    Elapsed: 0:33:56.\n",
            "  Batch 8,120  of  8,601.    Elapsed: 0:34:06.\n",
            "  Batch 8,160  of  8,601.    Elapsed: 0:34:16.\n",
            "  Batch 8,200  of  8,601.    Elapsed: 0:34:27.\n",
            "  Batch 8,240  of  8,601.    Elapsed: 0:34:37.\n",
            "  Batch 8,280  of  8,601.    Elapsed: 0:34:47.\n",
            "  Batch 8,320  of  8,601.    Elapsed: 0:34:57.\n",
            "  Batch 8,360  of  8,601.    Elapsed: 0:35:07.\n",
            "  Batch 8,400  of  8,601.    Elapsed: 0:35:17.\n",
            "  Batch 8,440  of  8,601.    Elapsed: 0:35:27.\n",
            "  Batch 8,480  of  8,601.    Elapsed: 0:35:37.\n",
            "  Batch 8,520  of  8,601.    Elapsed: 0:35:47.\n",
            "  Batch 8,560  of  8,601.    Elapsed: 0:35:57.\n",
            "  Batch 8,600  of  8,601.    Elapsed: 0:36:07.\n",
            "\n",
            "  Average training loss: 0.82\n",
            "  Training epoch took: 0:36:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.7820\n",
            "  Validation took: 0:01:36\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of  8,601.    Elapsed: 0:00:10.\n",
            "  Batch    80  of  8,601.    Elapsed: 0:00:20.\n",
            "  Batch   120  of  8,601.    Elapsed: 0:00:30.\n",
            "  Batch   160  of  8,601.    Elapsed: 0:00:40.\n",
            "  Batch   200  of  8,601.    Elapsed: 0:00:50.\n",
            "  Batch   240  of  8,601.    Elapsed: 0:01:00.\n",
            "  Batch   280  of  8,601.    Elapsed: 0:01:11.\n",
            "  Batch   320  of  8,601.    Elapsed: 0:01:21.\n",
            "  Batch   360  of  8,601.    Elapsed: 0:01:31.\n",
            "  Batch   400  of  8,601.    Elapsed: 0:01:41.\n",
            "  Batch   440  of  8,601.    Elapsed: 0:01:51.\n",
            "  Batch   480  of  8,601.    Elapsed: 0:02:01.\n",
            "  Batch   520  of  8,601.    Elapsed: 0:02:11.\n",
            "  Batch   560  of  8,601.    Elapsed: 0:02:21.\n",
            "  Batch   600  of  8,601.    Elapsed: 0:02:31.\n",
            "  Batch   640  of  8,601.    Elapsed: 0:02:41.\n",
            "  Batch   680  of  8,601.    Elapsed: 0:02:51.\n",
            "  Batch   720  of  8,601.    Elapsed: 0:03:02.\n",
            "  Batch   760  of  8,601.    Elapsed: 0:03:12.\n",
            "  Batch   800  of  8,601.    Elapsed: 0:03:22.\n",
            "  Batch   840  of  8,601.    Elapsed: 0:03:32.\n",
            "  Batch   880  of  8,601.    Elapsed: 0:03:42.\n",
            "  Batch   920  of  8,601.    Elapsed: 0:03:52.\n",
            "  Batch   960  of  8,601.    Elapsed: 0:04:02.\n",
            "  Batch 1,000  of  8,601.    Elapsed: 0:04:12.\n",
            "  Batch 1,040  of  8,601.    Elapsed: 0:04:22.\n",
            "  Batch 1,080  of  8,601.    Elapsed: 0:04:32.\n",
            "  Batch 1,120  of  8,601.    Elapsed: 0:04:42.\n",
            "  Batch 1,160  of  8,601.    Elapsed: 0:04:53.\n",
            "  Batch 1,200  of  8,601.    Elapsed: 0:05:03.\n",
            "  Batch 1,240  of  8,601.    Elapsed: 0:05:13.\n",
            "  Batch 1,280  of  8,601.    Elapsed: 0:05:23.\n",
            "  Batch 1,320  of  8,601.    Elapsed: 0:05:33.\n",
            "  Batch 1,360  of  8,601.    Elapsed: 0:05:43.\n",
            "  Batch 1,400  of  8,601.    Elapsed: 0:05:53.\n",
            "  Batch 1,440  of  8,601.    Elapsed: 0:06:03.\n",
            "  Batch 1,480  of  8,601.    Elapsed: 0:06:13.\n",
            "  Batch 1,520  of  8,601.    Elapsed: 0:06:23.\n",
            "  Batch 1,560  of  8,601.    Elapsed: 0:06:34.\n",
            "  Batch 1,600  of  8,601.    Elapsed: 0:06:44.\n",
            "  Batch 1,640  of  8,601.    Elapsed: 0:06:54.\n",
            "  Batch 1,680  of  8,601.    Elapsed: 0:07:04.\n",
            "  Batch 1,720  of  8,601.    Elapsed: 0:07:14.\n",
            "  Batch 1,760  of  8,601.    Elapsed: 0:07:24.\n",
            "  Batch 1,800  of  8,601.    Elapsed: 0:07:34.\n",
            "  Batch 1,840  of  8,601.    Elapsed: 0:07:44.\n",
            "  Batch 1,880  of  8,601.    Elapsed: 0:07:54.\n",
            "  Batch 1,920  of  8,601.    Elapsed: 0:08:04.\n",
            "  Batch 1,960  of  8,601.    Elapsed: 0:08:14.\n",
            "  Batch 2,000  of  8,601.    Elapsed: 0:08:25.\n",
            "  Batch 2,040  of  8,601.    Elapsed: 0:08:35.\n",
            "  Batch 2,080  of  8,601.    Elapsed: 0:08:45.\n",
            "  Batch 2,120  of  8,601.    Elapsed: 0:08:55.\n",
            "  Batch 2,160  of  8,601.    Elapsed: 0:09:05.\n",
            "  Batch 2,200  of  8,601.    Elapsed: 0:09:15.\n",
            "  Batch 2,240  of  8,601.    Elapsed: 0:09:25.\n",
            "  Batch 2,280  of  8,601.    Elapsed: 0:09:35.\n",
            "  Batch 2,320  of  8,601.    Elapsed: 0:09:45.\n",
            "  Batch 2,360  of  8,601.    Elapsed: 0:09:55.\n",
            "  Batch 2,400  of  8,601.    Elapsed: 0:10:06.\n",
            "  Batch 2,440  of  8,601.    Elapsed: 0:10:16.\n",
            "  Batch 2,480  of  8,601.    Elapsed: 0:10:26.\n",
            "  Batch 2,520  of  8,601.    Elapsed: 0:10:36.\n",
            "  Batch 2,560  of  8,601.    Elapsed: 0:10:46.\n",
            "  Batch 2,600  of  8,601.    Elapsed: 0:10:56.\n",
            "  Batch 2,640  of  8,601.    Elapsed: 0:11:06.\n",
            "  Batch 2,680  of  8,601.    Elapsed: 0:11:16.\n",
            "  Batch 2,720  of  8,601.    Elapsed: 0:11:26.\n",
            "  Batch 2,760  of  8,601.    Elapsed: 0:11:37.\n",
            "  Batch 2,800  of  8,601.    Elapsed: 0:11:47.\n",
            "  Batch 2,840  of  8,601.    Elapsed: 0:11:57.\n",
            "  Batch 2,880  of  8,601.    Elapsed: 0:12:07.\n",
            "  Batch 2,920  of  8,601.    Elapsed: 0:12:17.\n",
            "  Batch 2,960  of  8,601.    Elapsed: 0:12:27.\n",
            "  Batch 3,000  of  8,601.    Elapsed: 0:12:37.\n",
            "  Batch 3,040  of  8,601.    Elapsed: 0:12:47.\n",
            "  Batch 3,080  of  8,601.    Elapsed: 0:12:57.\n",
            "  Batch 3,120  of  8,601.    Elapsed: 0:13:07.\n",
            "  Batch 3,160  of  8,601.    Elapsed: 0:13:18.\n",
            "  Batch 3,200  of  8,601.    Elapsed: 0:13:28.\n",
            "  Batch 3,240  of  8,601.    Elapsed: 0:13:38.\n",
            "  Batch 3,280  of  8,601.    Elapsed: 0:13:48.\n",
            "  Batch 3,320  of  8,601.    Elapsed: 0:13:58.\n",
            "  Batch 3,360  of  8,601.    Elapsed: 0:14:08.\n",
            "  Batch 3,400  of  8,601.    Elapsed: 0:14:18.\n",
            "  Batch 3,440  of  8,601.    Elapsed: 0:14:28.\n",
            "  Batch 3,480  of  8,601.    Elapsed: 0:14:38.\n",
            "  Batch 3,520  of  8,601.    Elapsed: 0:14:48.\n",
            "  Batch 3,560  of  8,601.    Elapsed: 0:14:59.\n",
            "  Batch 3,600  of  8,601.    Elapsed: 0:15:09.\n",
            "  Batch 3,640  of  8,601.    Elapsed: 0:15:19.\n",
            "  Batch 3,680  of  8,601.    Elapsed: 0:15:29.\n",
            "  Batch 3,720  of  8,601.    Elapsed: 0:15:39.\n",
            "  Batch 3,760  of  8,601.    Elapsed: 0:15:49.\n",
            "  Batch 3,800  of  8,601.    Elapsed: 0:15:59.\n",
            "  Batch 3,840  of  8,601.    Elapsed: 0:16:09.\n",
            "  Batch 3,880  of  8,601.    Elapsed: 0:16:19.\n",
            "  Batch 3,920  of  8,601.    Elapsed: 0:16:29.\n",
            "  Batch 3,960  of  8,601.    Elapsed: 0:16:40.\n",
            "  Batch 4,000  of  8,601.    Elapsed: 0:16:50.\n",
            "  Batch 4,040  of  8,601.    Elapsed: 0:17:00.\n",
            "  Batch 4,080  of  8,601.    Elapsed: 0:17:10.\n",
            "  Batch 4,120  of  8,601.    Elapsed: 0:17:20.\n",
            "  Batch 4,160  of  8,601.    Elapsed: 0:17:30.\n",
            "  Batch 4,200  of  8,601.    Elapsed: 0:17:40.\n",
            "  Batch 4,240  of  8,601.    Elapsed: 0:17:50.\n",
            "  Batch 4,280  of  8,601.    Elapsed: 0:18:00.\n",
            "  Batch 4,320  of  8,601.    Elapsed: 0:18:10.\n",
            "  Batch 4,360  of  8,601.    Elapsed: 0:18:20.\n",
            "  Batch 4,400  of  8,601.    Elapsed: 0:18:31.\n",
            "  Batch 4,440  of  8,601.    Elapsed: 0:18:41.\n",
            "  Batch 4,480  of  8,601.    Elapsed: 0:18:51.\n",
            "  Batch 4,520  of  8,601.    Elapsed: 0:19:01.\n",
            "  Batch 4,560  of  8,601.    Elapsed: 0:19:11.\n",
            "  Batch 4,600  of  8,601.    Elapsed: 0:19:21.\n",
            "  Batch 4,640  of  8,601.    Elapsed: 0:19:31.\n",
            "  Batch 4,680  of  8,601.    Elapsed: 0:19:41.\n",
            "  Batch 4,720  of  8,601.    Elapsed: 0:19:51.\n",
            "  Batch 4,760  of  8,601.    Elapsed: 0:20:01.\n",
            "  Batch 4,800  of  8,601.    Elapsed: 0:20:12.\n",
            "  Batch 4,840  of  8,601.    Elapsed: 0:20:22.\n",
            "  Batch 4,880  of  8,601.    Elapsed: 0:20:32.\n",
            "  Batch 4,920  of  8,601.    Elapsed: 0:20:42.\n",
            "  Batch 4,960  of  8,601.    Elapsed: 0:20:52.\n",
            "  Batch 5,000  of  8,601.    Elapsed: 0:21:02.\n",
            "  Batch 5,040  of  8,601.    Elapsed: 0:21:12.\n",
            "  Batch 5,080  of  8,601.    Elapsed: 0:21:22.\n",
            "  Batch 5,120  of  8,601.    Elapsed: 0:21:32.\n",
            "  Batch 5,160  of  8,601.    Elapsed: 0:21:42.\n",
            "  Batch 5,200  of  8,601.    Elapsed: 0:21:52.\n",
            "  Batch 5,240  of  8,601.    Elapsed: 0:22:03.\n",
            "  Batch 5,280  of  8,601.    Elapsed: 0:22:13.\n",
            "  Batch 5,320  of  8,601.    Elapsed: 0:22:23.\n",
            "  Batch 5,360  of  8,601.    Elapsed: 0:22:33.\n",
            "  Batch 5,400  of  8,601.    Elapsed: 0:22:43.\n",
            "  Batch 5,440  of  8,601.    Elapsed: 0:22:53.\n",
            "  Batch 5,480  of  8,601.    Elapsed: 0:23:03.\n",
            "  Batch 5,520  of  8,601.    Elapsed: 0:23:13.\n",
            "  Batch 5,560  of  8,601.    Elapsed: 0:23:23.\n",
            "  Batch 5,600  of  8,601.    Elapsed: 0:23:33.\n",
            "  Batch 5,640  of  8,601.    Elapsed: 0:23:44.\n",
            "  Batch 5,680  of  8,601.    Elapsed: 0:23:54.\n",
            "  Batch 5,720  of  8,601.    Elapsed: 0:24:04.\n",
            "  Batch 5,760  of  8,601.    Elapsed: 0:24:14.\n",
            "  Batch 5,800  of  8,601.    Elapsed: 0:24:24.\n",
            "  Batch 5,840  of  8,601.    Elapsed: 0:24:34.\n",
            "  Batch 5,880  of  8,601.    Elapsed: 0:24:44.\n",
            "  Batch 5,920  of  8,601.    Elapsed: 0:24:54.\n",
            "  Batch 5,960  of  8,601.    Elapsed: 0:25:04.\n",
            "  Batch 6,000  of  8,601.    Elapsed: 0:25:14.\n",
            "  Batch 6,040  of  8,601.    Elapsed: 0:25:25.\n",
            "  Batch 6,080  of  8,601.    Elapsed: 0:25:35.\n",
            "  Batch 6,120  of  8,601.    Elapsed: 0:25:45.\n",
            "  Batch 6,160  of  8,601.    Elapsed: 0:25:55.\n",
            "  Batch 6,200  of  8,601.    Elapsed: 0:26:05.\n",
            "  Batch 6,240  of  8,601.    Elapsed: 0:26:15.\n",
            "  Batch 6,280  of  8,601.    Elapsed: 0:26:25.\n",
            "  Batch 6,320  of  8,601.    Elapsed: 0:26:35.\n",
            "  Batch 6,360  of  8,601.    Elapsed: 0:26:45.\n",
            "  Batch 6,400  of  8,601.    Elapsed: 0:26:55.\n",
            "  Batch 6,440  of  8,601.    Elapsed: 0:27:06.\n",
            "  Batch 6,480  of  8,601.    Elapsed: 0:27:16.\n",
            "  Batch 6,520  of  8,601.    Elapsed: 0:27:26.\n",
            "  Batch 6,560  of  8,601.    Elapsed: 0:27:36.\n",
            "  Batch 6,600  of  8,601.    Elapsed: 0:27:46.\n",
            "  Batch 6,640  of  8,601.    Elapsed: 0:27:56.\n",
            "  Batch 6,680  of  8,601.    Elapsed: 0:28:06.\n",
            "  Batch 6,720  of  8,601.    Elapsed: 0:28:16.\n",
            "  Batch 6,760  of  8,601.    Elapsed: 0:28:26.\n",
            "  Batch 6,800  of  8,601.    Elapsed: 0:28:36.\n",
            "  Batch 6,840  of  8,601.    Elapsed: 0:28:47.\n",
            "  Batch 6,880  of  8,601.    Elapsed: 0:28:57.\n",
            "  Batch 6,920  of  8,601.    Elapsed: 0:29:07.\n",
            "  Batch 6,960  of  8,601.    Elapsed: 0:29:17.\n",
            "  Batch 7,000  of  8,601.    Elapsed: 0:29:27.\n",
            "  Batch 7,040  of  8,601.    Elapsed: 0:29:37.\n",
            "  Batch 7,080  of  8,601.    Elapsed: 0:29:47.\n",
            "  Batch 7,120  of  8,601.    Elapsed: 0:29:57.\n",
            "  Batch 7,160  of  8,601.    Elapsed: 0:30:07.\n",
            "  Batch 7,200  of  8,601.    Elapsed: 0:30:17.\n",
            "  Batch 7,240  of  8,601.    Elapsed: 0:30:28.\n",
            "  Batch 7,280  of  8,601.    Elapsed: 0:30:38.\n",
            "  Batch 7,320  of  8,601.    Elapsed: 0:30:48.\n",
            "  Batch 7,360  of  8,601.    Elapsed: 0:30:58.\n",
            "  Batch 7,400  of  8,601.    Elapsed: 0:31:08.\n",
            "  Batch 7,440  of  8,601.    Elapsed: 0:31:18.\n",
            "  Batch 7,480  of  8,601.    Elapsed: 0:31:28.\n",
            "  Batch 7,520  of  8,601.    Elapsed: 0:31:38.\n",
            "  Batch 7,560  of  8,601.    Elapsed: 0:31:48.\n",
            "  Batch 7,600  of  8,601.    Elapsed: 0:31:58.\n",
            "  Batch 7,640  of  8,601.    Elapsed: 0:32:08.\n",
            "  Batch 7,680  of  8,601.    Elapsed: 0:32:19.\n",
            "  Batch 7,720  of  8,601.    Elapsed: 0:32:29.\n",
            "  Batch 7,760  of  8,601.    Elapsed: 0:32:39.\n",
            "  Batch 7,800  of  8,601.    Elapsed: 0:32:49.\n",
            "  Batch 7,840  of  8,601.    Elapsed: 0:32:59.\n",
            "  Batch 7,880  of  8,601.    Elapsed: 0:33:09.\n",
            "  Batch 7,920  of  8,601.    Elapsed: 0:33:19.\n",
            "  Batch 7,960  of  8,601.    Elapsed: 0:33:29.\n",
            "  Batch 8,000  of  8,601.    Elapsed: 0:33:39.\n",
            "  Batch 8,040  of  8,601.    Elapsed: 0:33:50.\n",
            "  Batch 8,080  of  8,601.    Elapsed: 0:34:00.\n",
            "  Batch 8,120  of  8,601.    Elapsed: 0:34:10.\n",
            "  Batch 8,160  of  8,601.    Elapsed: 0:34:20.\n",
            "  Batch 8,200  of  8,601.    Elapsed: 0:34:30.\n",
            "  Batch 8,240  of  8,601.    Elapsed: 0:34:40.\n",
            "  Batch 8,280  of  8,601.    Elapsed: 0:34:50.\n",
            "  Batch 8,320  of  8,601.    Elapsed: 0:35:00.\n",
            "  Batch 8,360  of  8,601.    Elapsed: 0:35:11.\n",
            "  Batch 8,400  of  8,601.    Elapsed: 0:35:21.\n",
            "  Batch 8,440  of  8,601.    Elapsed: 0:35:31.\n",
            "  Batch 8,480  of  8,601.    Elapsed: 0:35:41.\n",
            "  Batch 8,520  of  8,601.    Elapsed: 0:35:51.\n",
            "  Batch 8,560  of  8,601.    Elapsed: 0:36:01.\n",
            "  Batch 8,600  of  8,601.    Elapsed: 0:36:11.\n",
            "\n",
            "  Average training loss: 0.57\n",
            "  Training epoch took: 0:36:11\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.8055\n",
            "  Validation took: 0:01:37\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of  8,601.    Elapsed: 0:00:10.\n",
            "  Batch    80  of  8,601.    Elapsed: 0:00:20.\n",
            "  Batch   120  of  8,601.    Elapsed: 0:00:30.\n",
            "  Batch   160  of  8,601.    Elapsed: 0:00:40.\n",
            "  Batch   200  of  8,601.    Elapsed: 0:00:50.\n",
            "  Batch   240  of  8,601.    Elapsed: 0:01:01.\n",
            "  Batch   280  of  8,601.    Elapsed: 0:01:11.\n",
            "  Batch   320  of  8,601.    Elapsed: 0:01:21.\n",
            "  Batch   360  of  8,601.    Elapsed: 0:01:31.\n",
            "  Batch   400  of  8,601.    Elapsed: 0:01:41.\n",
            "  Batch   440  of  8,601.    Elapsed: 0:01:51.\n",
            "  Batch   480  of  8,601.    Elapsed: 0:02:01.\n",
            "  Batch   520  of  8,601.    Elapsed: 0:02:11.\n",
            "  Batch   560  of  8,601.    Elapsed: 0:02:21.\n",
            "  Batch   600  of  8,601.    Elapsed: 0:02:31.\n",
            "  Batch   640  of  8,601.    Elapsed: 0:02:41.\n",
            "  Batch   680  of  8,601.    Elapsed: 0:02:52.\n",
            "  Batch   720  of  8,601.    Elapsed: 0:03:02.\n",
            "  Batch   760  of  8,601.    Elapsed: 0:03:12.\n",
            "  Batch   800  of  8,601.    Elapsed: 0:03:22.\n",
            "  Batch   840  of  8,601.    Elapsed: 0:03:32.\n",
            "  Batch   880  of  8,601.    Elapsed: 0:03:42.\n",
            "  Batch   920  of  8,601.    Elapsed: 0:03:52.\n",
            "  Batch   960  of  8,601.    Elapsed: 0:04:02.\n",
            "  Batch 1,000  of  8,601.    Elapsed: 0:04:12.\n",
            "  Batch 1,040  of  8,601.    Elapsed: 0:04:22.\n",
            "  Batch 1,080  of  8,601.    Elapsed: 0:04:32.\n",
            "  Batch 1,120  of  8,601.    Elapsed: 0:04:42.\n",
            "  Batch 1,160  of  8,601.    Elapsed: 0:04:53.\n",
            "  Batch 1,200  of  8,601.    Elapsed: 0:05:03.\n",
            "  Batch 1,240  of  8,601.    Elapsed: 0:05:13.\n",
            "  Batch 1,280  of  8,601.    Elapsed: 0:05:23.\n",
            "  Batch 1,320  of  8,601.    Elapsed: 0:05:33.\n",
            "  Batch 1,360  of  8,601.    Elapsed: 0:05:43.\n",
            "  Batch 1,400  of  8,601.    Elapsed: 0:05:53.\n",
            "  Batch 1,440  of  8,601.    Elapsed: 0:06:03.\n",
            "  Batch 1,480  of  8,601.    Elapsed: 0:06:13.\n",
            "  Batch 1,520  of  8,601.    Elapsed: 0:06:23.\n",
            "  Batch 1,560  of  8,601.    Elapsed: 0:06:34.\n",
            "  Batch 1,600  of  8,601.    Elapsed: 0:06:44.\n",
            "  Batch 1,640  of  8,601.    Elapsed: 0:06:54.\n",
            "  Batch 1,680  of  8,601.    Elapsed: 0:07:04.\n",
            "  Batch 1,720  of  8,601.    Elapsed: 0:07:14.\n",
            "  Batch 1,760  of  8,601.    Elapsed: 0:07:24.\n",
            "  Batch 1,800  of  8,601.    Elapsed: 0:07:34.\n",
            "  Batch 1,840  of  8,601.    Elapsed: 0:07:44.\n",
            "  Batch 1,880  of  8,601.    Elapsed: 0:07:54.\n",
            "  Batch 1,920  of  8,601.    Elapsed: 0:08:04.\n",
            "  Batch 1,960  of  8,601.    Elapsed: 0:08:15.\n",
            "  Batch 2,000  of  8,601.    Elapsed: 0:08:25.\n",
            "  Batch 2,040  of  8,601.    Elapsed: 0:08:35.\n",
            "  Batch 2,080  of  8,601.    Elapsed: 0:08:45.\n",
            "  Batch 2,120  of  8,601.    Elapsed: 0:08:55.\n",
            "  Batch 2,160  of  8,601.    Elapsed: 0:09:05.\n",
            "  Batch 2,200  of  8,601.    Elapsed: 0:09:15.\n",
            "  Batch 2,240  of  8,601.    Elapsed: 0:09:25.\n",
            "  Batch 2,280  of  8,601.    Elapsed: 0:09:35.\n",
            "  Batch 2,320  of  8,601.    Elapsed: 0:09:45.\n",
            "  Batch 2,360  of  8,601.    Elapsed: 0:09:56.\n",
            "  Batch 2,400  of  8,601.    Elapsed: 0:10:06.\n",
            "  Batch 2,440  of  8,601.    Elapsed: 0:10:16.\n",
            "  Batch 2,480  of  8,601.    Elapsed: 0:10:26.\n",
            "  Batch 2,520  of  8,601.    Elapsed: 0:10:36.\n",
            "  Batch 2,560  of  8,601.    Elapsed: 0:10:46.\n",
            "  Batch 2,600  of  8,601.    Elapsed: 0:10:56.\n",
            "  Batch 2,640  of  8,601.    Elapsed: 0:11:06.\n",
            "  Batch 2,680  of  8,601.    Elapsed: 0:11:16.\n",
            "  Batch 2,720  of  8,601.    Elapsed: 0:11:26.\n",
            "  Batch 2,760  of  8,601.    Elapsed: 0:11:37.\n",
            "  Batch 2,800  of  8,601.    Elapsed: 0:11:47.\n",
            "  Batch 2,840  of  8,601.    Elapsed: 0:11:57.\n",
            "  Batch 2,880  of  8,601.    Elapsed: 0:12:07.\n",
            "  Batch 2,920  of  8,601.    Elapsed: 0:12:17.\n",
            "  Batch 2,960  of  8,601.    Elapsed: 0:12:27.\n",
            "  Batch 3,000  of  8,601.    Elapsed: 0:12:37.\n",
            "  Batch 3,040  of  8,601.    Elapsed: 0:12:47.\n",
            "  Batch 3,080  of  8,601.    Elapsed: 0:12:57.\n",
            "  Batch 3,120  of  8,601.    Elapsed: 0:13:07.\n",
            "  Batch 3,160  of  8,601.    Elapsed: 0:13:17.\n",
            "  Batch 3,200  of  8,601.    Elapsed: 0:13:28.\n",
            "  Batch 3,240  of  8,601.    Elapsed: 0:13:38.\n",
            "  Batch 3,280  of  8,601.    Elapsed: 0:13:48.\n",
            "  Batch 3,320  of  8,601.    Elapsed: 0:13:58.\n",
            "  Batch 3,360  of  8,601.    Elapsed: 0:14:08.\n",
            "  Batch 3,400  of  8,601.    Elapsed: 0:14:18.\n",
            "  Batch 3,440  of  8,601.    Elapsed: 0:14:28.\n",
            "  Batch 3,480  of  8,601.    Elapsed: 0:14:38.\n",
            "  Batch 3,520  of  8,601.    Elapsed: 0:14:48.\n",
            "  Batch 3,560  of  8,601.    Elapsed: 0:14:58.\n",
            "  Batch 3,600  of  8,601.    Elapsed: 0:15:09.\n",
            "  Batch 3,640  of  8,601.    Elapsed: 0:15:19.\n",
            "  Batch 3,680  of  8,601.    Elapsed: 0:15:29.\n",
            "  Batch 3,720  of  8,601.    Elapsed: 0:15:39.\n",
            "  Batch 3,760  of  8,601.    Elapsed: 0:15:49.\n",
            "  Batch 3,800  of  8,601.    Elapsed: 0:15:59.\n",
            "  Batch 3,840  of  8,601.    Elapsed: 0:16:09.\n",
            "  Batch 3,880  of  8,601.    Elapsed: 0:16:19.\n",
            "  Batch 3,920  of  8,601.    Elapsed: 0:16:29.\n",
            "  Batch 3,960  of  8,601.    Elapsed: 0:16:39.\n",
            "  Batch 4,000  of  8,601.    Elapsed: 0:16:50.\n",
            "  Batch 4,040  of  8,601.    Elapsed: 0:17:00.\n",
            "  Batch 4,080  of  8,601.    Elapsed: 0:17:10.\n",
            "  Batch 4,120  of  8,601.    Elapsed: 0:17:20.\n",
            "  Batch 4,160  of  8,601.    Elapsed: 0:17:30.\n",
            "  Batch 4,200  of  8,601.    Elapsed: 0:17:40.\n",
            "  Batch 4,240  of  8,601.    Elapsed: 0:17:50.\n",
            "  Batch 4,280  of  8,601.    Elapsed: 0:18:00.\n",
            "  Batch 4,320  of  8,601.    Elapsed: 0:18:10.\n",
            "  Batch 4,360  of  8,601.    Elapsed: 0:18:20.\n",
            "  Batch 4,400  of  8,601.    Elapsed: 0:18:31.\n",
            "  Batch 4,440  of  8,601.    Elapsed: 0:18:41.\n",
            "  Batch 4,480  of  8,601.    Elapsed: 0:18:51.\n",
            "  Batch 4,520  of  8,601.    Elapsed: 0:19:01.\n",
            "  Batch 4,560  of  8,601.    Elapsed: 0:19:11.\n",
            "  Batch 4,600  of  8,601.    Elapsed: 0:19:21.\n",
            "  Batch 4,640  of  8,601.    Elapsed: 0:19:31.\n",
            "  Batch 4,680  of  8,601.    Elapsed: 0:19:41.\n",
            "  Batch 4,720  of  8,601.    Elapsed: 0:19:51.\n",
            "  Batch 4,760  of  8,601.    Elapsed: 0:20:01.\n",
            "  Batch 4,800  of  8,601.    Elapsed: 0:20:12.\n",
            "  Batch 4,840  of  8,601.    Elapsed: 0:20:22.\n",
            "  Batch 4,880  of  8,601.    Elapsed: 0:20:32.\n",
            "  Batch 4,920  of  8,601.    Elapsed: 0:20:42.\n",
            "  Batch 4,960  of  8,601.    Elapsed: 0:20:52.\n",
            "  Batch 5,000  of  8,601.    Elapsed: 0:21:02.\n",
            "  Batch 5,040  of  8,601.    Elapsed: 0:21:12.\n",
            "  Batch 5,080  of  8,601.    Elapsed: 0:21:22.\n",
            "  Batch 5,120  of  8,601.    Elapsed: 0:21:32.\n",
            "  Batch 5,160  of  8,601.    Elapsed: 0:21:42.\n",
            "  Batch 5,200  of  8,601.    Elapsed: 0:21:53.\n",
            "  Batch 5,240  of  8,601.    Elapsed: 0:22:03.\n",
            "  Batch 5,280  of  8,601.    Elapsed: 0:22:13.\n",
            "  Batch 5,320  of  8,601.    Elapsed: 0:22:23.\n",
            "  Batch 5,360  of  8,601.    Elapsed: 0:22:33.\n",
            "  Batch 5,400  of  8,601.    Elapsed: 0:22:43.\n",
            "  Batch 5,440  of  8,601.    Elapsed: 0:22:53.\n",
            "  Batch 5,480  of  8,601.    Elapsed: 0:23:03.\n",
            "  Batch 5,520  of  8,601.    Elapsed: 0:23:13.\n",
            "  Batch 5,560  of  8,601.    Elapsed: 0:23:23.\n",
            "  Batch 5,600  of  8,601.    Elapsed: 0:23:34.\n",
            "  Batch 5,640  of  8,601.    Elapsed: 0:23:44.\n",
            "  Batch 5,680  of  8,601.    Elapsed: 0:23:54.\n",
            "  Batch 5,720  of  8,601.    Elapsed: 0:24:04.\n",
            "  Batch 5,760  of  8,601.    Elapsed: 0:24:14.\n",
            "  Batch 5,800  of  8,601.    Elapsed: 0:24:24.\n",
            "  Batch 5,840  of  8,601.    Elapsed: 0:24:34.\n",
            "  Batch 5,880  of  8,601.    Elapsed: 0:24:44.\n",
            "  Batch 5,920  of  8,601.    Elapsed: 0:24:54.\n",
            "  Batch 5,960  of  8,601.    Elapsed: 0:25:04.\n",
            "  Batch 6,000  of  8,601.    Elapsed: 0:25:15.\n",
            "  Batch 6,040  of  8,601.    Elapsed: 0:25:25.\n",
            "  Batch 6,080  of  8,601.    Elapsed: 0:25:35.\n",
            "  Batch 6,120  of  8,601.    Elapsed: 0:25:45.\n",
            "  Batch 6,160  of  8,601.    Elapsed: 0:25:55.\n",
            "  Batch 6,200  of  8,601.    Elapsed: 0:26:05.\n",
            "  Batch 6,240  of  8,601.    Elapsed: 0:26:15.\n",
            "  Batch 6,280  of  8,601.    Elapsed: 0:26:25.\n",
            "  Batch 6,320  of  8,601.    Elapsed: 0:26:35.\n",
            "  Batch 6,360  of  8,601.    Elapsed: 0:26:45.\n",
            "  Batch 6,400  of  8,601.    Elapsed: 0:26:56.\n",
            "  Batch 6,440  of  8,601.    Elapsed: 0:27:06.\n",
            "  Batch 6,480  of  8,601.    Elapsed: 0:27:16.\n",
            "  Batch 6,520  of  8,601.    Elapsed: 0:27:26.\n",
            "  Batch 6,560  of  8,601.    Elapsed: 0:27:36.\n",
            "  Batch 6,600  of  8,601.    Elapsed: 0:27:46.\n",
            "  Batch 6,640  of  8,601.    Elapsed: 0:27:56.\n",
            "  Batch 6,680  of  8,601.    Elapsed: 0:28:06.\n",
            "  Batch 6,720  of  8,601.    Elapsed: 0:28:16.\n",
            "  Batch 6,760  of  8,601.    Elapsed: 0:28:26.\n",
            "  Batch 6,800  of  8,601.    Elapsed: 0:28:37.\n",
            "  Batch 6,840  of  8,601.    Elapsed: 0:28:47.\n",
            "  Batch 6,880  of  8,601.    Elapsed: 0:28:57.\n",
            "  Batch 6,920  of  8,601.    Elapsed: 0:29:07.\n",
            "  Batch 6,960  of  8,601.    Elapsed: 0:29:17.\n",
            "  Batch 7,000  of  8,601.    Elapsed: 0:29:27.\n",
            "  Batch 7,040  of  8,601.    Elapsed: 0:29:37.\n",
            "  Batch 7,080  of  8,601.    Elapsed: 0:29:47.\n",
            "  Batch 7,120  of  8,601.    Elapsed: 0:29:57.\n",
            "  Batch 7,160  of  8,601.    Elapsed: 0:30:07.\n",
            "  Batch 7,200  of  8,601.    Elapsed: 0:30:18.\n",
            "  Batch 7,240  of  8,601.    Elapsed: 0:30:28.\n",
            "  Batch 7,280  of  8,601.    Elapsed: 0:30:38.\n",
            "  Batch 7,320  of  8,601.    Elapsed: 0:30:48.\n",
            "  Batch 7,360  of  8,601.    Elapsed: 0:30:58.\n",
            "  Batch 7,400  of  8,601.    Elapsed: 0:31:08.\n",
            "  Batch 7,440  of  8,601.    Elapsed: 0:31:18.\n",
            "  Batch 7,480  of  8,601.    Elapsed: 0:31:28.\n",
            "  Batch 7,520  of  8,601.    Elapsed: 0:31:38.\n",
            "  Batch 7,560  of  8,601.    Elapsed: 0:31:49.\n",
            "  Batch 7,600  of  8,601.    Elapsed: 0:31:59.\n",
            "  Batch 7,640  of  8,601.    Elapsed: 0:32:09.\n",
            "  Batch 7,680  of  8,601.    Elapsed: 0:32:19.\n",
            "  Batch 7,720  of  8,601.    Elapsed: 0:32:29.\n",
            "  Batch 7,760  of  8,601.    Elapsed: 0:32:39.\n",
            "  Batch 7,800  of  8,601.    Elapsed: 0:32:49.\n",
            "  Batch 7,840  of  8,601.    Elapsed: 0:32:59.\n",
            "  Batch 7,880  of  8,601.    Elapsed: 0:33:09.\n",
            "  Batch 7,920  of  8,601.    Elapsed: 0:33:19.\n",
            "  Batch 7,960  of  8,601.    Elapsed: 0:33:30.\n",
            "  Batch 8,000  of  8,601.    Elapsed: 0:33:40.\n",
            "  Batch 8,040  of  8,601.    Elapsed: 0:33:50.\n",
            "  Batch 8,080  of  8,601.    Elapsed: 0:34:00.\n",
            "  Batch 8,120  of  8,601.    Elapsed: 0:34:10.\n",
            "  Batch 8,160  of  8,601.    Elapsed: 0:34:20.\n",
            "  Batch 8,200  of  8,601.    Elapsed: 0:34:30.\n",
            "  Batch 8,240  of  8,601.    Elapsed: 0:34:40.\n",
            "  Batch 8,280  of  8,601.    Elapsed: 0:34:50.\n",
            "  Batch 8,320  of  8,601.    Elapsed: 0:35:00.\n",
            "  Batch 8,360  of  8,601.    Elapsed: 0:35:11.\n",
            "  Batch 8,400  of  8,601.    Elapsed: 0:35:21.\n",
            "  Batch 8,440  of  8,601.    Elapsed: 0:35:31.\n",
            "  Batch 8,480  of  8,601.    Elapsed: 0:35:41.\n",
            "  Batch 8,520  of  8,601.    Elapsed: 0:35:51.\n",
            "  Batch 8,560  of  8,601.    Elapsed: 0:36:01.\n",
            "  Batch 8,600  of  8,601.    Elapsed: 0:36:11.\n",
            "\n",
            "  Average training loss: 0.45\n",
            "  Training epoch took: 0:36:11\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.8122\n",
            "  Validation took: 0:01:37\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X-2OkKUjB2w",
        "colab_type": "code",
        "outputId": "eaac8077-dcaa-48ac-c7f5-d4e21e1f4b93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "8e41733c61dc42e5bffb96eb30947ab4",
            "2d397cc5cad147dbb110f29d9fdd7d94",
            "0e3023c1223846c4ab5bb978b9ba9eb4",
            "b8e37cc712c441c582b0a1128bfe5509",
            "758fda1a456a45f6a8b4417e032c6d22",
            "0cee41494a1244a2b087fa0c0c9d0ef5",
            "9349dd5e89bf4b3ea70fef54c8c195e1",
            "4430fa5f6fed4576bb72aaed63a1de25"
          ]
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in tqdm(sentences_test):\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent, max_length = 256,                    # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=256, value=1,\n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i!=1) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(y_test)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e41733c61dc42e5bffb96eb30947ab4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10150.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_fW5lrcjxlX",
        "colab_type": "code",
        "outputId": "e3513f3c-b126-4b66-cae0-35f7c0445f16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "a34763eed54d479abedbdd866cb3846b",
            "f60b7e513357405fb1651cec170acdd4",
            "db0bf61aa71f43c5a4739bf079493852",
            "6bc11978be3c44b6bc6c346a231c9dfe",
            "57281bcfa5854d46ac23ee14e4bc9ca2",
            "d16397d4f94541afa966bd5695ee1c06",
            "0859adba0df446e3b0a58fae5c6948f0",
            "ec2d1dd4268f40288cab99aae8fe6424"
          ]
        }
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in tqdm(prediction_dataloader):\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(np.argmax(logits, axis=1).flatten())\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 10,150 test sentences...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a34763eed54d479abedbdd866cb3846b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=318.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y4T9fQnj16V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions  = np.concatenate(predictions)\n",
        "true_labels = np.concatenate(true_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTq2Jjzaj84O",
        "colab_type": "code",
        "outputId": "009978e3-2594-4e5b-ba7e-7aadfa18da61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#test\n",
        "from sklearn.metrics import f1_score\n",
        "print('f1-micro: ', f1_score(true_labels, predictions, average='micro')*100)\n",
        "print('f1-weighted: ', f1_score(true_labels, predictions, average='weighted')*100) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1-micro:  74.46305418719213\n",
            "f1-weighted:  74.35299219628398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC48gjGqjyzV",
        "colab_type": "code",
        "outputId": "f7d72493-8c57-47ba-b151-caa766497fe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#val\n",
        "from sklearn.metrics import f1_score\n",
        "print('f1-micro: ', f1_score(true_labels, predictions, average='micro')*100)\n",
        "print('f1-weighted: ', f1_score(true_labels, predictions, average='weighted')*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1-micro:  81.2237503088199\n",
            "f1-weighted:  81.20123944010427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUPcsaEEmnId",
        "colab_type": "code",
        "outputId": "c1f7b26f-1a23-4979-d35c-8134452440f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#train\n",
        "from sklearn.metrics import f1_score\n",
        "print('f1-micro: ', f1_score(true_labels, predictions, average='micro')*100)\n",
        "print('f1-weighted: ', f1_score(true_labels, predictions, average='weighted')*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1-micro:  89.96729888816219\n",
            "f1-weighted:  89.96249572847556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzwMC-WmUWz2",
        "colab_type": "code",
        "outputId": "9fee96fb-2a5f-480b-c128-4ee5fdb84368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#test translated\n",
        "from sklearn.metrics import f1_score\n",
        "print('f1-micro: ', f1_score(true_labels, predictions, average='micro')*100)\n",
        "print('f1-weighted: ', f1_score(true_labels, predictions, average='weighted')*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1-micro:  82.65024630541872\n",
            "f1-weighted:  82.67452751994799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rervN6rAKW8J",
        "colab_type": "code",
        "outputId": "e578712e-ef55-4a5f-baf8-d9f23cc73ae3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(true_labels, predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.84      0.85      1325\n",
            "           1       0.79      0.83      0.81      2166\n",
            "           2       0.86      0.87      0.86       978\n",
            "           3       0.75      0.90      0.81       173\n",
            "           4       0.83      0.77      0.80       473\n",
            "           5       0.84      0.85      0.84      1480\n",
            "           6       0.78      0.80      0.79      1723\n",
            "           7       0.87      0.81      0.84      1832\n",
            "\n",
            "    accuracy                           0.83     10150\n",
            "   macro avg       0.82      0.83      0.83     10150\n",
            "weighted avg       0.83      0.83      0.83     10150\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQj0acBISERD",
        "colab_type": "code",
        "outputId": "d94798ca-87db-4dea-e65f-0b4f7d973e3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(true_labels, predictions)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.84      0.78      1325\n",
            "           1       0.68      0.74      0.71      2166\n",
            "           2       0.82      0.72      0.77       978\n",
            "           3       0.74      0.50      0.60       173\n",
            "           4       0.67      0.79      0.73       473\n",
            "           5       0.76      0.61      0.68      1480\n",
            "           6       0.77      0.78      0.78      1723\n",
            "           7       0.80      0.78      0.79      1832\n",
            "\n",
            "    accuracy                           0.74     10150\n",
            "   macro avg       0.75      0.72      0.73     10150\n",
            "weighted avg       0.75      0.74      0.74     10150\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF6sNa57ip8j",
        "colab_type": "code",
        "outputId": "99c9e068-686c-447c-e42e-f0959f18529b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(true_labels, predictions, normalize=None)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1115   80   33    6   30   15   39    7]\n",
            " [ 149 1602   74   15   57  122   89   58]\n",
            " [  89  131  708    6   10    8    6   20]\n",
            " [  31   37    3   87    3    2    4    6]\n",
            " [  13   42    1    0  373   14   18   12]\n",
            " [  58  341    2    0   49  899   70   61]\n",
            " [  61   70   16    1   10   32 1352  181]\n",
            " [  23   65   30    2   23   89  178 1422]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqKANYnGnvgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lens = []\n",
        "for i, text in enumerate(test_texts):\n",
        "    if y_test[i] == 3:\n",
        "        lens.append(len(text.split()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORl70nQMoFs3",
        "colab_type": "code",
        "outputId": "1dd0c6fb-6bc8-4c67-a954-2ff4ca9d2377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.mean(lens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "107.77456647398844"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3suB7zucoX9Q",
        "colab_type": "code",
        "outputId": "159e95f8-017e-4273-ddcf-b58993288253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_labels[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['G', 'H', 'A', 'B', 'E', 'E', 'G', 'H', 'H', 'F']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgLVW6WWojN4",
        "colab_type": "code",
        "outputId": "4b264315-54ea-4a02-bbb1-b6dd4994f009",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "predictions[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 0, 0, 1, 4, 0, 6, 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGqvJuMXolCi",
        "colab_type": "code",
        "outputId": "91abecc2-9b97-413b-c33d-8ae52fa7a7f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_labels[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['G', 'H', 'A', 'B', 'E', 'E', 'G', 'H', 'H', 'F']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhOAfW-IobBC",
        "colab_type": "code",
        "outputId": "f19cd5bf-9de5-437f-83a9-e84feee5bbdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(test_texts[1].split())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8gP94Ugodvo",
        "colab_type": "code",
        "outputId": "9c2fa5dc-ffb5-4e19-dfa7-bd0bbe32744b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "test_texts[2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'использование сельское хозяйство и биотехнология. сущность изобретения растения регенеранты получают путем посадки стерильных эксплантов на питательную среду для каллусообразования, субкультивирования и индукции растений регенератов. при этом в качестве питательной среды используют среду мурасиге скуга, содержащую макро и микроэлементы, сахарозу, инозит, а также агар агар в количестве мг л, тиамин мг л, пиридоксин, мг л и никотиновую кислоту, мг л. на этапе каллусообразования в среду дополнительно вводят, дихлорфеноксиуксусную кислоту, мг л и бензиламинопурин, мг л, а на этапе субкультивирования каллуса в среду вводят, мг л, дихлорфеноксиуксусной кислоты'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    }
  ]
}